projects:
    - link: https://github.com/EnronMusk/MorseLLM
      title: Morse Code Transformer
      authors: Luke Rivard
      abstract: I implemented the transformer architecture from scratch. I trained two LLMs, one on english characters and another on morse encoded english characters. I found that increasing ONLY the context length proportionally yielded similar performance between the morse code and english LLM.
      image: /images/transformer.PNG
    - link: https://github.com/EnronMusk/multi_implicit_cot
      title: Multi-Implicit Chain of Thought Reasoning via Knowledge Distillation
      authors: Luke Rivard
      abstract: I expanded upon a paper by training the LLM to perform simultaneous 2x2 inference using the same knowledge distillation process all packaged up in a nice and easy to use notebook.
      image: /images/implicit_cot_large_cropped_2x.gif
    - link: https://github.com/EnronMusk/MyRepo/tree/main/ReviewGPT
      title: ChatGPT vs Supervised ML
      authors: Luke Rivard
      abstract: I trained a NN, RNN and GBM to predict amazon review scores from keywords and compared to ChatGPT using the openAI API. The results demonstrated that ChatGPT understands context by significantly outperforming traditional keyword models in binary score prediction.
      image: /images/openai.png
    - link: https://github.com/EnronMusk/2me3project
      title: Zoomerified Java Code Compiler
      authors: Luke Rivard
      abstract: This is just a silly project I did for a course. I created a Java program that emulates a compiler. The emulated compiler takes in "Zoomerfied" Java structured code and parses, compiles and runs its translated java program.
      image: /images/emoji.png
